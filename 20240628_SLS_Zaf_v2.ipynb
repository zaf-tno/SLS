{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title   : Script for combining raw SLS .txt files, plotting columns and adding them to an exported file with sheets combining all raw data\n",
    "\n",
    "Author  : Zaf Khalil\n",
    "\n",
    "Date    : 28-June-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib==3.10.1 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from -r requirements.txt (line 2)) (3.10.1)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from -r requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from matplotlib==3.10.1->-r requirements.txt (line 2)) (3.2.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from openpyxl==3.1.5->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khalilj\\appdata\\local\\miniforge3\\envs\\analysis\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 1)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Producing a .txt file with the list of installed packages and their versions\n",
    "# !pip freeze > requirements.txt\n",
    "# import pkg_resources\n",
    "\n",
    "# # List of required packages\n",
    "# required_packages = [\n",
    "#     \"pandas\",\n",
    "#     \"matplotlib\",\n",
    "#     \"openpyxl\"\n",
    "# ]\n",
    "\n",
    "# # Get installed packages and their versions\n",
    "# installed_packages = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "\n",
    "# # Filter only the required ones\n",
    "# with open(\"requirements.txt\", \"w\") as f:\n",
    "#     for package in required_packages:\n",
    "#         if package in installed_packages:\n",
    "#             f.write(f\"{package}=={installed_packages[package]}\\n\")\n",
    "\n",
    "# print(\"Filtered requirements.txt generated successfully.\")\n",
    "\n",
    "# To install the packages listed in requirements.txt, use the following command:\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Load this first to make sure the libraries are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.chart import LineChart, Reference\n",
    "from openpyxl.chart.axis import ChartLines\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining .txt raw files in one excel sheet\n",
    "This section will import the raw data in a specified path and will combine all found files in one output xlsx file\n",
    "The files have to be the raw .txt files from the SLS export options.\n",
    "\n",
    "1- Put the script file in the folder that contains a subfolder of the raw data\n",
    "\n",
    "2- Insert the name of the raw data subfolder as a raw_directory\n",
    "\n",
    "3- Choose a name for the file containing combined raw data as sheets\n",
    "\n",
    "4- Run the cell\n",
    "\n",
    "The output will be found in the main folder in which the script is placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to combined sheets.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and output filename\n",
    "raw_directory = 'rawdata'                                                                          # Raw data folder name in the directory\n",
    "combined_sheets_filename = 'combined sheets.xlsx'                                                   # Name of the file in which all sheets are to be combined\n",
    "dfs = {}                                                                                        # Creating an empty dataframe\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(raw_directory):                                                      \n",
    "    if filename.endswith(\".txt\"):                                                               # Condition to fine .txt files in the directory\n",
    "        file_path = os.path.join(raw_directory, filename)                                       # Creating a temp datafile name by combining the found file name and the directory to be read\n",
    "\n",
    "        # Read the main data, skipping the first 41 rows\n",
    "        main_data = pd.read_csv(                                                                \n",
    "            file_path,                                                                          # Opens the current file in the for-loop\n",
    "            skiprows=41,                                                                        # skips 41 rows, and reads the remainder of the data\n",
    "            sep='\\t', encoding='latin1',\n",
    "            skipfooter=1,\n",
    "            engine='python'\n",
    "        )\n",
    "        \n",
    "        # Read the first 17 rows of the original file\n",
    "        first_17_rows = pd.read_csv(                                                            \n",
    "            file_path, nrows=16,                                                                # Opens the current file and extracts 16 rows\n",
    "            skiprows=lambda x: x==8,                                                            # Skips only the 9th row\n",
    "            sep='\\t', encoding='latin1',\n",
    "            header=None                                                                         # Does not extract a header\n",
    "        )\n",
    "        # Read the transmittance rows in the raw data files\n",
    "        transmittance_rows = pd.read_csv(                                                                   \n",
    "            file_path, nrows=2,                                                                 # Opens the current file again and extract only 2 row\n",
    "            skiprows=18,                                                                        # Skips 18 rows and extracts the 19th and 20th rows based on the previous line\n",
    "            sep='\\t', encoding='latin1',\n",
    "            header=None\n",
    "        )\n",
    "\n",
    "        # Read the data ID row in the raw data files\n",
    "        ID_row = pd.read_csv(                                                                   \n",
    "            file_path, nrows=1,                                                                 # Opens the current file again and extract only 1 row\n",
    "            skiprows=37,                                                                        # Skips 37 rows and extracts the 38th row based on the previous line\n",
    "            sep='\\t', encoding='latin1',\n",
    "            header=None\n",
    "        )\n",
    "\n",
    "        # Read the reflextive index rows in the raw data files\n",
    "        reflect_sample_info_rows = pd.read_csv(                                                                   \n",
    "            file_path, nrows=7,                                                                 # Opens the current file again and extract 7 rows\n",
    "            skiprows=25,                                                                        # Skips 25 rows and extracts the rows based on the previous line\n",
    "            sep='\\t', encoding='latin1',\n",
    "            header=None\n",
    "        )\n",
    "\n",
    "        empty_row = pd.Series([None])                                                           # Creates an empty row to add to the next data frame (avoids having one of the values being added as a header by concat)\n",
    "        first_17_rows = pd.concat(\n",
    "            [empty_row,\n",
    "             ID_row,\n",
    "             first_17_rows,\n",
    "             transmittance_rows,\n",
    "             reflect_sample_info_rows\n",
    "            ],\n",
    "            ignore_index=True\n",
    "        )                                                                                       # Combines the extracted rows above in one data frame\n",
    "\n",
    "        # Add the first 17 rows as new columns to the main DataFrame\n",
    "        main_data2 = pd.concat([main_data, first_17_rows], axis=1)                              \n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        dfs[filename] = main_data2\n",
    "\n",
    "# Write all DataFrames to an Excel file with each DataFrame in a separate sheet                 \n",
    "with pd.ExcelWriter(combined_sheets_filename, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in dfs.items():\n",
    "        # Use the file name without extension as the sheet name\n",
    "        df.to_excel(writer, index=False, sheet_name=os.path.splitext(sheet_name[:31])[0])       # Sheet_name[-31:] is used to rename the new sheets using the last 31 characters of the original sheets. If the first 31 characters are identical, excel will overwrite sheets and not all data will be outputted.\n",
    "\n",
    "print(f\"Data has been written to {combined_sheets_filename}\")                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part saves the plots as adjustable excel charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved and Excel file 'Output\\output.xlsx' created.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the Excel file with multiple sheets\n",
    "file_path = combined_sheets_filename                                                        # Replace with your Excel file path --> the variable here matches the name of the exported combined sheets after importation above.\n",
    "xls = pd.ExcelFile(file_path)                                                               # Opens/reads the target excel file (with combined raw data values)\n",
    "\n",
    "# Step 2: Create the output subfolder\n",
    "output_file_name = 'output.xlsx'                                                           # Choose a name for the output file (data, sample name, user name, etc)\n",
    "output_folder = 'Output'                                                            # Choose a name for the output folder to be created\n",
    "if not os.path.exists(output_folder):                                                       # Checks if the name does not already excists, if it exists, it will use it, if not, it will create a new folder\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Step 3: Initialize a writer for the output Excel file in the output subfolder\n",
    "# This creates a variable in which a funciton is used to combine a directory and an output file name. Basically creating a name for the output file in the output folder.\n",
    "output_file = os.path.join(output_folder, output_file_name)                                 \n",
    "\n",
    "#The writer function is defined and the engine is xlswriter. This will 'write' the final results in an output file.\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')   \n",
    "\n",
    "# Step 4: Iterate through each sheet, create scatter plots with straight lines, and save them on each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    # Truncate the sheet name to 31 characters if necessary\n",
    "    # (this is because writer encouters issues when trying to name sheets with more than 31 characters)\n",
    "    truncated_sheet_name = sheet_name[:31]\n",
    "\n",
    "    # Read each sheet into a DataFrame\n",
    "    df2 = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "\n",
    "    # Write the DataFrame to the Excel writer\n",
    "    # Here you see that the written name of the sheets in the new output file is the one with a maximum of 31 characters\n",
    "    df2.to_excel(writer, sheet_name=truncated_sheet_name, index=False)                      \n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects. (Basically, opening a new file to write the save the new output in it)\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[truncated_sheet_name]\n",
    "\n",
    "    # Create a new scatter chart object\n",
    "    chart = workbook.add_chart({'type': 'scatter', 'subtype': 'straight'})                  # Scatter plot with straight line is needed in order to have a value-based x-axis. Otherwise, logarithmic view of x-axis is not possible\n",
    "\n",
    "    # Since we plot 2 lines and use 2 y-axes, we will have to define to series and each will be assigned a different y-axis and have different properties.\n",
    "    # Configure the first series\n",
    "    chart.add_series({\n",
    "        'name':       df2.columns[1],                                                       # The title of the first series data\n",
    "        'categories': [truncated_sheet_name, 1, 0, len(df2), 0],                            # defining the dimensions of the data (sheetname, first_row, first_col, last_row (len gives the total length, used as last row number), last_col (we are plotting one column here to first_col and last_col are the same))\n",
    "        'values':     [truncated_sheet_name, 1, 1, len(df2), 1],                            # Adjust based on your data range (Choosing the data range to be plotted)\n",
    "        'y2_axis':    False,                                                                # Here we switch off the second y-axis for the first series and have the main y-axis on by default.\n",
    "        'marker':     {'type': 'none'},                                                     # Hide markers\n",
    "        'line':       {'color': 'black', 'width': 1},                                       # Set the color of the line\n",
    "    })\n",
    "\n",
    "    # Configure the second series for the secondary y-axis\n",
    "    chart.add_series({\n",
    "        'name':       df2.columns[2],                                                       # The title of the first series data\n",
    "        'categories': [truncated_sheet_name, 1, 0, len(df2), 0],                            # defining the dimensions of the data\n",
    "        'values':     [truncated_sheet_name, 1, 2, len(df2), 2],                            # Adjust based on your data range\n",
    "        'y2_axis':    True,                                                                 # Here we switch on the second y-axis for the second series.\n",
    "        'marker':     {'type': 'none'},                                                     # Hide markers\n",
    "        'line':       {'color': 'blue', 'dash_type': 'dash', 'width': 1},                   # Set the color of the line\n",
    "    })\n",
    "\n",
    "    # Add a chart title and some axis labels, configuration of the main chart\n",
    "    chart.set_title({'name': f'{truncated_sheet_name} Plot',                                # The title of the entire chart/plot\n",
    "                     'name_font': {'size':12}\n",
    "                    })                               \n",
    "    \n",
    "    # Configuration of the x-axis of the main plot\n",
    "    chart.set_x_axis({                                                                      # Properties of the x-axis\n",
    "        'name': df2.columns[0],                                                             # title of the x-axis\n",
    "        'min': 0.1, 'max':5000,                                                             # range of the x-axis\n",
    "        'log_base': 10,                                                                     # logarithmic scaling\n",
    "        'crossing':0.1,                                                                     # defining location of the y-axis\n",
    "        'major_gridlines': {'visible': True, 'line': {'color': 'gray', 'width': 0.5}},      # adding major gridlines\n",
    "        'minor_gridlines': {'visible': True, 'line': {'color': '#DCD8D8', 'width': 0.5}}    # adding minor gridlines\n",
    "    })\n",
    "    # Configuration of the first y-axis\n",
    "    chart.set_y_axis({                                                                      \n",
    "        #'name': df2.columns[1],                                                            # The title of the axis. Can either match the original header or add the title you want after the : in ''\n",
    "        'max': 20,                                                                          # Setting maximum value of the axis\n",
    "        'major_gridlines':{'visible':False}                                                 # Hiding the horizontal gridlines\n",
    "    })\n",
    "    # Configuration of the second y-axis\n",
    "    chart.set_y2_axis({\n",
    "        #'name': df2.columns[2],                                                            # This makes the title matches the original title in the header of the raw data\n",
    "        'name': 'Cumulative (%)',                                                           # This is a user chosen title\n",
    "        'max': 100,                                                                         # Setting maximum value of the axis\n",
    "        'major_gridlines':{'visible':False}                                                 # Hiding the horizontal gridlines of the second y-axis\n",
    "    })\n",
    "\n",
    "    # Set the size of the chart\n",
    "    chart.set_size({'width': 400, 'height': 350})                                           # Set chart size (width x height)\n",
    "\n",
    "    # Set the legend position to the bottom\n",
    "    chart.set_legend({'position': 'bottom'})\n",
    "\n",
    "    # Insert the chart into the worksheet (in output file)\n",
    "    worksheet.insert_chart('I4', chart)\n",
    "\n",
    "# Step 5: Save the Excel file with inserted charts as \"[output file name].xlsx\"\n",
    "writer.close()\n",
    "\n",
    "print(f\"Plots saved and Excel file '{output_file}' created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
